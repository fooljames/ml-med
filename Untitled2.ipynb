{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/pandas_profiling/base.py:20: UserWarning:\n",
      "\n",
      "\n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-2490361fa671>\", line 3, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 72, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import tools\n",
    "from utils import *\n",
    "import pandas_profiling\n",
    "import datetime \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "philips_path = '/Users/tniyomkarn/KKU_med/data/philips'\n",
    "capsule_path = '/Users/tniyomkarn/KKU_med/data/capsule'\n",
    "output_path = '/Users/tniyomkarn/KKU_med/data/output'\n",
    "follow_path = '/Users/tniyomkarn/KKU_med/data/followup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171219\n",
      "already saved file 20171231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (58,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171224\n",
      "already saved file 20171230\n",
      "already saved file 20171218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (58,138) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171226\n",
      "already saved file 20171227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (73,138) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171223\n",
      "already saved file 20171222\n",
      "already saved file 20171208\n",
      "already saved file 20171209\n",
      "already saved file 20171221\n",
      "already saved file 20171118\n",
      "already saved file 20171124\n",
      "already saved file 20171130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171125\n",
      "already saved file 20171119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (58,61,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171127\n",
      "already saved file 20180109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20180108\n",
      "already saved file 20171126\n",
      "already saved file 20171122\n",
      "already saved file 20171123\n",
      "already saved file 20171121\n",
      "already saved file 20171120\n",
      "already saved file 20180103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (53,58,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20180117\n",
      "already saved file 20180116\n",
      "already saved file 20180102\n",
      "already saved file 20171112\n",
      "already saved file 20180114\n",
      "already saved file 20180115\n",
      "already saved file 20171113\n",
      "already saved file 20171117\n",
      "already saved file 20180111\n",
      "already saved file 20180105\n",
      "already saved file 20180104\n",
      "already saved file 20180110\n",
      "already saved file 20171116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (61,73,138) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171114\n",
      "already saved file 20171128\n",
      "already saved file 20180106\n",
      "already saved file 20180112\n",
      "already saved file 20180113\n",
      "already saved file 20180107\n",
      "already saved file 20171129\n",
      "already saved file 20171115\n",
      "already saved file 20171210\n",
      "already saved file 20171204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning:\n",
      "\n",
      "Columns (53,73) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already saved file 20171205\n",
      "already saved file 20171211\n",
      "already saved file 20171207\n",
      "already saved file 20171213\n",
      "already saved file 20171212\n",
      "already saved file 20171206\n",
      "already saved file 20171202\n",
      "already saved file 20171216\n",
      "already saved file 20171217\n",
      "already saved file 20171203\n",
      "already saved file 20171215\n",
      "already saved file 20171201\n",
      "already saved file 20171229\n",
      "already saved file 20171228\n",
      "already saved file 20171214\n"
     ]
    }
   ],
   "source": [
    "# # create list datadate of output file for checking \n",
    "# def merge_file(phlilps_path, capsule_path, output_path):\n",
    "    \n",
    "#     phlilps_list = glob.glob(phlilps_path + \"/phlilps*.csv\")\n",
    "#     capsule_list = glob.glob(capsule_path + \"/capsule*.csv\")\n",
    "#     output_list = glob.glob(output_path + \"/output*.csv\")\n",
    "#     output_file = [ x[46:54] for x in output_list]\n",
    "\n",
    "#     for i, p in enumerate(phlilps_list):\n",
    "#         date_file = p[47:55]\n",
    "#         if date_file in output_file:  \n",
    "#             print('output_%s already existed' %date_file)\n",
    "        \n",
    "#         else:    \n",
    "#             for j, c in enumerate(capsule_list):\n",
    "#                 if  date_file == c[47:55]:\n",
    "#                     phlilps = load_data(p,phlilps_path + '/column_id_name_p.csv')\n",
    "#                     #phlilps = mean_interval(phlilps)\n",
    "#                     phlilps = addTimeInSec(phlilps)\n",
    "#                     phlilps = mean_by_interval(phlilps, 10)\n",
    "#                     ##phlilps = y_moving_avg(phlilps)\n",
    "#                     del phlilps['diff_time']\n",
    "\n",
    "#                     capsules = load_data(c,capsule_path + '/column_id_name_c.csv')\n",
    "#                     capsules = addTimeInSec(capsules)\n",
    "#                     capsules = mean_by_interval(capsules, 10)\n",
    "\n",
    "#                     df = pd.merge(left = capsules, right = phlilps, how = 'inner', on=['dataset_datetime', 'dataset_location'])\n",
    "#                     #df.to_hdf(output_path + '/output_' + date_file + '.h5', index = False, key = 'output')\n",
    "#                     df.to_csv(output_path + '/output_' + date_file + '.csv', index = False)\n",
    "#                     print(\"already saved file %s\" %date_file)\n",
    "                    \n",
    "                    \n",
    "merge_file(philips_path, capsule_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171218.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171230.csv with rows: 24536 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171224.csv with rows: 574 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171225.csv with rows: 3317 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171231.csv with rows: 14208 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171219.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171227.csv with rows: 9273 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171226.csv with rows: 9983 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171222.csv with rows: 3672 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171223.csv with rows: 57 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171221.csv with rows: 2217 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171209.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171208.csv with rows: 16 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171119.csv with rows: 21958 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171125.csv with rows: 21544 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171130.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171124.csv with rows: 25239 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171118.csv with rows: 8361 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180108.csv with rows: 33330 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171126.csv with rows: 21544 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171127.csv with rows: 19327 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180109.csv with rows: 21384 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171123.csv with rows: 19726 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171122.csv with rows: 10070 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171120.csv with rows: 22901 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171121.csv with rows: 17569 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180102.csv with rows: 25334 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180116.csv with rows: 16884 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180117.csv with rows: 8756 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180103.csv with rows: 22211 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180115.csv with rows: 16848 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171113.csv with rows: 13879 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171112.csv with rows: 13929 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180114.csv with rows: 12983 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180110.csv with rows: 20966 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180104.csv with rows: 26479 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171116.csv with rows: 9513 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171117.csv with rows: 9880 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180105.csv with rows: 26373 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180111.csv with rows: 24477 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180107.csv with rows: 27467 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180113.csv with rows: 10439 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171115.csv with rows: 9887 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171129.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171128.csv with rows: 11680 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171114.csv with rows: 11561 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180112.csv with rows: 22056 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20180106.csv with rows: 18366 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171211.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171205.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171204.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171210.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171206.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171212.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171213.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171207.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171203.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171217.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171216.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171202.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171214.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171228.csv with rows: 12071 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171229.csv with rows: 21218 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171201.csv with rows: 0 \n",
      "Loaded file /Users/tniyomkarn/KKU_med/data/output/output_20171215.csv with rows: 0 \n"
     ]
    }
   ],
   "source": [
    "# def load_data_output(datapath):\n",
    "    \n",
    "#     #file_list = glob.glob(datapath + \"/output*.h5\")\n",
    "#     file_list = glob.glob(datapath + \"/output*.csv\")\n",
    "#     data = pd.DataFrame()\n",
    "#     list_ = []\n",
    "#     for file_ in file_list:\n",
    "#         if file_ == file_list[0]:\n",
    "#             df = pd.read_csv(file_, low_memory=False, index_col=None)\n",
    "#         else:\n",
    "#             df = pd.read_csv(file_, low_memory=False, index_col=None , header = 0)\n",
    "#         data = data.append(df)\n",
    "#         print(\"Loaded file %s with rows: %d \" %(file_, len(df)))\n",
    "        \n",
    "#     data.index = range(len(data))\n",
    "#     data = data.drop_duplicates()\n",
    "#     data['dataset_datetime'] = pd.to_datetime(data['datetime_interval_x'], format='%Y-%m-%d %H:%M:%S',)\n",
    "#     return data\n",
    "    \n",
    "df = load_data_output(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MICU2-6FL-B2', 'MICU2-6FL-B5', 'MICU2-6FL-B6', 'MICU2-6FL-B7',\n",
       "       'MICU2-6FL-B3', 'MICU2-6FL-B8', 'MICU2-6FL-B4', 'MICU2-6FL-B1',\n",
       "       'MICU1-7FL-B5', 'MICU1-7FL-B6'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset_location.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First admit & Follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['dataset_datetime']\n",
    "rolling_mean = df.groupby('dataset_location')['SpO2'].rolling('600s').mean().reset_index()\n",
    "rolling_mean.rename(columns={'SpO2': 'SpO2_moving_avg'}, inplace=True)\n",
    "df = pd.merge(df, rolling_mean, on = ['dataset_location', 'dataset_datetime'])\n",
    "#df['SpO2_moving_avg'] = df.groupby('dataset_location')['SpO2'].rolling('600s').mean().reset_index(0,drop=True)\n",
    "df['SpO2_change'] = df['SpO2'] - df['SpO2_moving_avg']\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_y(df, t = '180s', n_decrease_lower_bound = 0.8, delta_change = -3.0):\n",
    "#     df.sort_values(by = ['dataset_location','dataset_datetime'], inplace = True)\n",
    "#     df.index = df['dataset_datetime']\n",
    "#     df['check'] = np.where(df['SpO2_change'] <= delta_change, 1, 0)\n",
    "    \n",
    "#     summ = lambda x: x.rolling(t).sum()\n",
    "#     count = lambda x: x.rolling(t).count()\n",
    "#     df['data_count'] = df.groupby('dataset_location')['check'].apply(summ)\n",
    "#     df['y_check_decrease'] = df.groupby('dataset_location')['check'].apply(count) / df['data_count']\n",
    "    \n",
    "#     #df.columns.str.lower()\n",
    "#     #setting_cols = [col for col in df.columns if 'setting' in col or 'mode' in col]\n",
    "#     #df['is_setting_changed'] = df[setting_cols].rolling('3600s', center = True).std().max().max() > 0\n",
    "#     df['y_value'] = np.where(df['SpO2'].isnull() == True, 0, 0)\n",
    "#     df['y_value'] = np.where((df['check'] == 1) & (df['y_check_decrease'] >= n_decrease_lower_bound) & (df['data_count'] > int(t[:3])/20) , 1, df['y_value']) #& (df['is_setting_changed'])\n",
    "\n",
    "#     df['sum_y_value'] = df.groupby('dataset_location')['y_value'].apply(summ)\n",
    "#     df['y_value'] = np.where((df['y_value'] == 1) & (df['sum_y_value'] == 1), 1, 0)\n",
    "#     #     del df['check']\n",
    "#     sum5 = lambda x: x.rolling('300s').sum()\n",
    "#     sum10 = lambda x: x.rolling('600s').sum()\n",
    "#     df['data_y_5m'] = df.groupby('dataset_location')['y_value'].apply(sum5)\n",
    "#     df['data_y_10m'] = df.groupby('dataset_location')['y_value'].apply(sum10)\n",
    "#     df['y_diff'] = df['data_y_10m'] - df['data_y_5m']\n",
    "#     df['y_flag'] = np.where(df['y_diff'] > 0, 1,0)\n",
    "\n",
    "#     del df['data_y_5m']\n",
    "#     del df['data_y_10m']\n",
    "#     del df['y_diff']\n",
    "#     df.index = range(len(df))\n",
    "    \n",
    "#     return df\n",
    "\n",
    "df = check_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_yx(df, t = '180s', n_decrease_lower_bound = 6, delta_change = -0.1):\n",
    "#     df.sort_values(by = ['dataset_location','dataset_datetime'], inplace = True)\n",
    "#     df.index = df['dataset_datetime']\n",
    "#     df['check'] = np.where(df['SpO2_change'] <= delta_change, 1, 0)\n",
    "#     f = lambda x: x.rolling(t).sum()\n",
    "#     df['y_check_decrease'] = df.groupby('dataset_location')['check'].apply(f)\n",
    "    \n",
    "#     #df.columns.str.lower()\n",
    "#     #setting_cols = [col for col in df.columns if 'setting' in col or 'mode' in col]\n",
    "#     #df['is_setting_changed'] = df[setting_cols].rolling('3600s', center = True).std().max().max() > 0\n",
    "#     df['y_value'] = np.where(df['SpO2'].isnull() == True, 'NA', 0)\n",
    "#     df['y_value'] = np.where((df['check'] == 1) & (df['y_check_decrease'] >= n_decrease_lower_bound) , 1, df['y_value']) #& (df['is_setting_changed'])\n",
    "#     del df['check']\n",
    "#     df.index = range(len(df))\n",
    "#     return df\n",
    "\n",
    "# dfx = check_yx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_location\n",
       "MICU1-7FL-B5      3179\n",
       "MICU1-7FL-B6      5171\n",
       "MICU2-6FL-B1    130994\n",
       "MICU2-6FL-B2    120930\n",
       "MICU2-6FL-B3     99078\n",
       "MICU2-6FL-B4     14213\n",
       "MICU2-6FL-B5    178190\n",
       "MICU2-6FL-B6     68711\n",
       "MICU2-6FL-B7     25353\n",
       "MICU2-6FL-B8     37036\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['dataset_location']).size()\n",
    "# df[(df['dataset_datetime'].dt.hour == 22) & (df['dataset_datetime'].dt.day == 24)][['dataset_location', 'dataset_datetime', 'check', 'y_check_decrease', 'y_value']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_flag\n",
       "0    671008\n",
       "1     11847\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['y_flag']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['y_value'] == 1][['y_value', 'sum_y_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/tniyomkarn/KKU_med/ml-med/MICU2-6FL-B5.html'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = 'MICU2-6FL-B5'\n",
    "df_locat = df[df['dataset_location'] == location].copy()\n",
    "# df_locat = dfx[dfx['dataset_location'] == location].copy()\n",
    "df_locat['y_value_1'] = np.where(df_locat['y_value'] == 1, df_locat['SpO2'], float('nan') )\n",
    "\n",
    "traces = []\n",
    "\n",
    "for i, col in enumerate(['SpO2', 'SpO2_moving_avg']):\n",
    "    traces.append(go.Scatter(\n",
    "                    x = df_locat.dataset_datetime,\n",
    "                    y = df_locat[col],\n",
    "                    mode = 'lines',\n",
    "                    name = col\n",
    "                    ))\n",
    "    \n",
    "traces.append(go.Scatter(\n",
    "            x = df_locat.dataset_datetime,\n",
    "            y = df_locat.y_value_1,\n",
    "            mode = 'markers',\n",
    "            marker = dict(color = 'rgb(255,0,0)'),\n",
    "            name = \"'y'\"\n",
    "            ))\n",
    "\n",
    "traces.append(go.Scatter(\n",
    "                    x = df_locat.dataset_datetime,\n",
    "                    y = df_locat['SpO2_change'],\n",
    "                    mode = 'lines',\n",
    "                    name = \"'SpO2_change'\",\n",
    "                    yaxis = 'y2' \n",
    "                    ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = location,\n",
    "    yaxis2=dict(\n",
    "        overlaying='y',\n",
    "        color = '',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data = traces, layout = layout)\n",
    "plot(fig, filename = location + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, t_moving = '180s', t_before = '600s', n_before = 6):\n",
    "    data = df.copy()\n",
    "    cols = ['Respiratory Rate', 'Mean Airway Pressure', 'Inspired Tidal Volume', 'SpO2']\n",
    "    \n",
    "    # Moving Average ############################################################################################\n",
    "    data.sort_values(by = ['dataset_location','dataset_datetime'], inplace = True)\n",
    "    data.index = data['dataset_datetime']\n",
    "    mean = data.groupby('dataset_location')[cols].rolling(t_moving).mean().reset_index()\n",
    "    #mean.rename(columns = {col: '{}_{}'.format(col, 'moving_mean_avg') for col in (cols)}, inplace = True)\n",
    "    sd = data.groupby('dataset_location')[cols].rolling(t_moving).std().reset_index()\n",
    "    #sd.rename(columns = {col: '{}_{}'.format(col, 'moving_sd_avg') for col in (cols)}, inplace = True)\n",
    "    \n",
    "    for i, col in enumerate(cols):\n",
    "        colname = col + \"_moving_mean_avg\"\n",
    "        data[colname] = mean[col]\n",
    "        colname = col + \"_moving_sd_avg\"\n",
    "        data[colname] = sd[col]\n",
    "    \n",
    "    # Average Before ###########################################################################################\n",
    "    from datetime import timedelta\n",
    "    mean_bf = data.groupby(['dataset_location'])[cols].rolling(t_before).mean().reset_index()\n",
    "    sd_bf = data.groupby(['dataset_location'])[cols].rolling(t_before).std().reset_index()\n",
    "    \n",
    "    time_delta = []\n",
    "    for i in range(1,n_before+1):\n",
    "        time_delta.append(int(t_before[0:3])*i)\n",
    "    \n",
    "    \n",
    "    for i, s in enumerate(time_delta):\n",
    "        col_name = 'datetime_' + str(s) + \"s_bf\"\n",
    "        data[col_name] = data['dataset_datetime'] - timedelta(seconds = s)\n",
    "        \n",
    "        mean_df = mean_bf.copy()\n",
    "        mean_df = mean_df.rename(columns = {'dataset_datetime':col_name})\n",
    "        mean_df.rename(columns={col:'{}_{}'.format(col, 'mean' + str(s) +'s') for col in (cols)}, inplace=True)\n",
    "        data = pd.merge(left = data, right = mean_df, how='left', left_on = [col_name, 'dataset_location'],\n",
    "                      right_on = [col_name, 'dataset_location'])\n",
    "        \n",
    "        std_df = sd_bf.copy()\n",
    "        std_df = std_df.rename(columns = {'dataset_datetime':col_name})\n",
    "        std_df.rename(columns={col:'{}_{}'.format(col,'std' + str(s) +'s') for col in (cols)}, inplace=True)\n",
    "        data = pd.merge(left = data, right = std_df, how='left', left_on = [col_name, 'dataset_location'],\n",
    "                      right_on = [col_name, 'dataset_location'])\n",
    "        \n",
    "    data.index = range(len(data))\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c8809a389a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dfa199f62370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Respiratory Rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean Airway Pressure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Inspired Tidal Volume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mncolumn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"datetime\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "features = ['dataset_location', 'Respiratory Rate', 'Mean Airway Pressure', 'Inspired Tidal Volume']\n",
    "features.extend(list(data.columns)[ncolumn:])\n",
    "features = [x for x in features if \"datetime\" not in x ]\n",
    "x_data = data[features]\n",
    "y_data = data['y_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f11e14789083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m train_features, test_features, train_target, test_target = train_test_split(x_data, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                                             \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                             \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_data' is not defined"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "test_size = 0.25\n",
    "train_features, test_features, train_target, test_target = train_test_split(x_data, \n",
    "                                                                            y_data, \n",
    "                                                                            test_size = test_size, \n",
    "                                                                            random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4b9d5ab41d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mrandomly\u001b[0m \u001b[0mtweaked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m x_train, x_validation, y_train, y_validation = train_test_split(train_features,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                  \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                  \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "oversampling by SMOTE alorithm: creates aynthetic observations of the minority class by\n",
    "- Finding the k-nearest-neighbors for minority class observations (finding similar observations)\n",
    "- Randomly choosing one of the k-nearest-neighbors and using it to create a similar, \n",
    "but randomly tweaked, new observation. \n",
    "\"\"\"\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(train_features,\n",
    "                                                 train_target,\n",
    "                                                 test_size = test_size,\n",
    "                                                 random_state = seed)\n",
    "\n",
    "sm = SMOTE(random_state = seed, ratio = 1.0)  # class ratio of 1\n",
    "x_res, y_res = sm.fit_sample(x_train, y_train)\n",
    "print(y_train.value_counts(), np.bincount(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-43b5a8dce223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Algorithm gradient boosting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Algorithm gradient boosting\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6a59bdeef512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_features' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(test_features)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2703b8c38b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_target, predictions)\n",
    "print(\"Accuracy: %.2f\" %(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multiple Processing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'moving_avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-47c87bd3f1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoving_avg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'moving_avg' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = moving_avg(df)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fb6cb15d08e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "df_new = check_y(df_new)\n",
    "(df_new['y_value'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
