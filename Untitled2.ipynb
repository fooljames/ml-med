{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/pandas_profiling/base.py:20: UserWarning:\n",
      "\n",
      "\n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-a5ffc29f7ef7>\", line 3, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 72, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "# from utils_ing import *\n",
    "from utils import *\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import tools\n",
    "\n",
    "import pandas_profiling\n",
    "import datetime \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "philips_path = '/Users/tniyomkarn/KKU-med/data/philips'\n",
    "capsule_path = '/Users/tniyomkarn/KKU-med/data/capsule'\n",
    "output_path = '/Users/tniyomkarn/KKU-med/data/output'\n",
    "follow_path = '/Users/tniyomkarn/KKU-med/data/followup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file /Users/tniyomkarn/KKU-med/data/output/output_20171125.csv with rows: 409 \n",
      "Loaded file /Users/tniyomkarn/KKU-med/data/output/output_20171124.csv with rows: 680 \n",
      "Loaded file /Users/tniyomkarn/KKU-med/data/output/output_20171126.csv with rows: 409 \n",
      "Loaded file /Users/tniyomkarn/KKU-med/data/output/output_20171127.csv with rows: 504 \n"
     ]
    }
   ],
   "source": [
    "def load_data_output(datapath):\n",
    "    \n",
    "    #file_list = glob.glob(datapath + \"/output*.h5\")\n",
    "    file_list = glob.glob(datapath + \"/output*.csv\")\n",
    "    data = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for file_ in file_list:\n",
    "        if file_ == file_list[0]:\n",
    "            df = pd.read_csv(file_, low_memory=False, index_col=None)\n",
    "        else:\n",
    "            df = pd.read_csv(file_, low_memory=False, index_col=None , header = 0)\n",
    "        data = data.append(df)\n",
    "        print(\"Loaded file %s with rows: %d \" %(file_, len(df)))\n",
    "        \n",
    "    data.index = range(len(data))\n",
    "    data = data.drop_duplicates()\n",
    "    data['dataset_datetime'] = pd.to_datetime(data['dataset_datetime'], format='%Y-%m-%d %H:%M:%S',)\n",
    "    return data\n",
    "    \n",
    "df = load_data_output(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MICU2-6FL-B5', 'MICU2-6FL-B3', 'MICU2-6FL-B2', 'MICU2-6FL-B1',\n",
       "       'MICU2-6FL-B7'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dataset_location.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First admit & Follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "window must be an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0aae46353a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrolling_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpO2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'600s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrolling_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'SpO2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'SpO2_moving_avg'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrolling_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset_datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df['SpO2_moving_avg'] = df.groupby('dataset_location')['SpO2'].rolling('600s').mean().reset_index(0,drop=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpO2_percent_change'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpO2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpO2_moving_avg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mrolling\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \"\"\"\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRollingGroupby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRollingGroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'groupby'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/core/window.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_groupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_groupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGroupByMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/core/window.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, window, min_periods, freq, center, win_type, axis, on, closed, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwin_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/core/window.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window must be an integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window must be non-negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: window must be an integer"
     ]
    }
   ],
   "source": [
    "rolling_mean = df.groupby('dataset_location')['SpO2'].rolling('600s').mean().reset_index()\n",
    "rolling_mean.rename(columns={'SpO2': 'SpO2_moving_avg'}, inplace=True)\n",
    "df = pd.merge(df, rolling_mean, on = ['dataset_location', 'dataset_datetime'])\n",
    "#df['SpO2_moving_avg'] = df.groupby('dataset_location')['SpO2'].rolling('600s').mean().reset_index(0,drop=True)\n",
    "df['SpO2_percent_change'] = df['SpO2'] - df['SpO2_moving_avg']\n",
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_interval_x</th>\n",
       "      <th>dataset_location</th>\n",
       "      <th>dataset_datetime</th>\n",
       "      <th>Expired O2</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>Inspired O2 (FiO2)</th>\n",
       "      <th>Mean Airway Pressure</th>\n",
       "      <th>Dynamic Compliance</th>\n",
       "      <th>Respiration Rate Setting</th>\n",
       "      <th>Minute Volume (Spontaneous)</th>\n",
       "      <th>...</th>\n",
       "      <th>ST lead I</th>\n",
       "      <th>ST lead II</th>\n",
       "      <th>ST lead III</th>\n",
       "      <th>ST aVR</th>\n",
       "      <th>ST aVL</th>\n",
       "      <th>ST aVF</th>\n",
       "      <th>PPV</th>\n",
       "      <th>time_in_sec_y</th>\n",
       "      <th>SpO2_moving_avg</th>\n",
       "      <th>SpO2_percent_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-25 02:53:10</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125025310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511578390</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-25 02:54:30</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125025430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511578470</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-25 03:09:10</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125030910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511579350</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-25 03:18:30</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125031830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511579910</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-25 03:19:10</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125031910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511579950</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   datetime_interval_x dataset_location              dataset_datetime  \\\n",
       "0  2017-11-25 02:53:10     MICU2-6FL-B1 1970-01-01 05:36:11.125025310   \n",
       "1  2017-11-25 02:54:30     MICU2-6FL-B1 1970-01-01 05:36:11.125025430   \n",
       "2  2017-11-25 03:09:10     MICU2-6FL-B1 1970-01-01 05:36:11.125030910   \n",
       "3  2017-11-25 03:18:30     MICU2-6FL-B1 1970-01-01 05:36:11.125031830   \n",
       "4  2017-11-25 03:19:10     MICU2-6FL-B1 1970-01-01 05:36:11.125031910   \n",
       "\n",
       "   Expired O2  Respiratory Rate  Inspired O2 (FiO2)  Mean Airway Pressure  \\\n",
       "0         NaN              21.0                 NaN                  10.0   \n",
       "1         NaN              21.0                 NaN                  11.0   \n",
       "2         NaN              19.0                 NaN                   8.0   \n",
       "3         NaN               NaN                 NaN                   NaN   \n",
       "4         NaN               NaN                 NaN                   NaN   \n",
       "\n",
       "   Dynamic Compliance  Respiration Rate Setting  Minute Volume (Spontaneous)  \\\n",
       "0                42.0                       NaN                          0.0   \n",
       "1                41.0                       NaN                          0.0   \n",
       "2                75.0                       NaN                          0.0   \n",
       "3                 NaN                       NaN                          NaN   \n",
       "4                 NaN                       NaN                          NaN   \n",
       "\n",
       "          ...           ST lead I  ST lead II  ST lead III  ST aVR  ST aVL  \\\n",
       "0         ...                 0.2         NaN          NaN     NaN     NaN   \n",
       "1         ...                 0.1         NaN          NaN     NaN     NaN   \n",
       "2         ...                 NaN         NaN          NaN     NaN     NaN   \n",
       "3         ...                 0.2         NaN          NaN     NaN     NaN   \n",
       "4         ...                 0.0         NaN          NaN     NaN     NaN   \n",
       "\n",
       "   ST aVF  PPV  time_in_sec_y  SpO2_moving_avg  SpO2_percent_change  \n",
       "0     NaN  NaN     1511578390            100.0                  0.0  \n",
       "1     NaN  NaN     1511578470            100.0                  0.0  \n",
       "2     NaN  NaN     1511579350            100.0                  0.0  \n",
       "3     NaN  NaN     1511579910            100.0                  0.0  \n",
       "4     NaN  NaN     1511579950            100.0                  0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/03 Project/01 KKU MLMED/data/check.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-50bb7c34ad2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset_datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D:/03 Project/01 KKU MLMED/data/check.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1522\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1524\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1627\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1628\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/03 Project/01 KKU MLMED/data/check.csv'"
     ]
    }
   ],
   "source": [
    "df.sort_values(by = ['dataset_location', 'dataset_datetime']).head(100).to_csv('D:/03 Project/01 KKU MLMED/data/check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_y(df, t = '180s', n_decrease_lower_bound = 6, delta_change = -0.1):\n",
    "    \n",
    "    df.sort_values(by = ['dataset_location','dataset_datetime'], inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_y(df, t = '180s', n_decrease_lower_bound = 6, delta_change = -0.1):\n",
    "    df.sort_values(by = ['dataset_location','dataset_datetime'], inplace = True)\n",
    "    df.index = df['dataset_datetime']\n",
    "    df['check'] = np.where(df['SpO2_percent_change'] <= delta_change, 1, 0)\n",
    "    f = lambda x: x.rolling(t).sum()\n",
    "    df['y_check_decrease'] = df.groupby('dataset_location')['check'].apply(f)\n",
    "    \n",
    "    #df.columns.str.lower()\n",
    "    #setting_cols = [col for col in df.columns if 'setting' in col or 'mode' in col]\n",
    "    #df['is_setting_changed'] = df[setting_cols].rolling('3600s', center = True).std().max().max() > 0\n",
    "    df['y_value'] = np.where(df['SpO2'].isnull() == True, 'NA', 0)\n",
    "    df['y_value'] = np.where((df['check'] == 1) & (df['y_check_decrease'] >= n_decrease_lower_bound) , 1, df['y_value']) #& (df['is_setting_changed'])\n",
    "    del df['check']\n",
    "    df.index = range(len(df))\n",
    "    return df\n",
    "\n",
    "df = check_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_interval_x</th>\n",
       "      <th>dataset_location</th>\n",
       "      <th>dataset_datetime</th>\n",
       "      <th>Expired O2</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>Inspired O2 (FiO2)</th>\n",
       "      <th>Mean Airway Pressure</th>\n",
       "      <th>Dynamic Compliance</th>\n",
       "      <th>Respiration Rate Setting</th>\n",
       "      <th>Minute Volume (Spontaneous)</th>\n",
       "      <th>...</th>\n",
       "      <th>ST lead III</th>\n",
       "      <th>ST aVR</th>\n",
       "      <th>ST aVL</th>\n",
       "      <th>ST aVF</th>\n",
       "      <th>PPV</th>\n",
       "      <th>time_in_sec_y</th>\n",
       "      <th>SpO2_moving_avg</th>\n",
       "      <th>SpO2_percent_change</th>\n",
       "      <th>y_check_decrease</th>\n",
       "      <th>y_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-25 02:53:10</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125025310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511578390</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-25 02:54:30</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125025430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511578470</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-25 03:09:10</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125030910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511579350</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-25 03:18:30</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125031830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511579910</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-25 03:19:10</td>\n",
       "      <td>MICU2-6FL-B1</td>\n",
       "      <td>1970-01-01 05:36:11.125031910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1511579950</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   datetime_interval_x dataset_location              dataset_datetime  \\\n",
       "0  2017-11-25 02:53:10     MICU2-6FL-B1 1970-01-01 05:36:11.125025310   \n",
       "1  2017-11-25 02:54:30     MICU2-6FL-B1 1970-01-01 05:36:11.125025430   \n",
       "2  2017-11-25 03:09:10     MICU2-6FL-B1 1970-01-01 05:36:11.125030910   \n",
       "3  2017-11-25 03:18:30     MICU2-6FL-B1 1970-01-01 05:36:11.125031830   \n",
       "4  2017-11-25 03:19:10     MICU2-6FL-B1 1970-01-01 05:36:11.125031910   \n",
       "\n",
       "   Expired O2  Respiratory Rate  Inspired O2 (FiO2)  Mean Airway Pressure  \\\n",
       "0         NaN              21.0                 NaN                  10.0   \n",
       "1         NaN              21.0                 NaN                  11.0   \n",
       "2         NaN              19.0                 NaN                   8.0   \n",
       "3         NaN               NaN                 NaN                   NaN   \n",
       "4         NaN               NaN                 NaN                   NaN   \n",
       "\n",
       "   Dynamic Compliance  Respiration Rate Setting  Minute Volume (Spontaneous)  \\\n",
       "0                42.0                       NaN                          0.0   \n",
       "1                41.0                       NaN                          0.0   \n",
       "2                75.0                       NaN                          0.0   \n",
       "3                 NaN                       NaN                          NaN   \n",
       "4                 NaN                       NaN                          NaN   \n",
       "\n",
       "    ...     ST lead III  ST aVR  ST aVL  ST aVF  PPV  time_in_sec_y  \\\n",
       "0   ...             NaN     NaN     NaN     NaN  NaN     1511578390   \n",
       "1   ...             NaN     NaN     NaN     NaN  NaN     1511578470   \n",
       "2   ...             NaN     NaN     NaN     NaN  NaN     1511579350   \n",
       "3   ...             NaN     NaN     NaN     NaN  NaN     1511579910   \n",
       "4   ...             NaN     NaN     NaN     NaN  NaN     1511579950   \n",
       "\n",
       "   SpO2_moving_avg  SpO2_percent_change  y_check_decrease  y_value  \n",
       "0            100.0                  0.0               0.0        0  \n",
       "1            100.0                  0.0               0.0        0  \n",
       "2            100.0                  0.0               0.0        0  \n",
       "3            100.0                  0.0               0.0        0  \n",
       "4            100.0                  0.0               0.0        0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_value\n",
       "0     1138\n",
       "NA     455\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['y_value']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/tniyomkarn/KKU-med/ml-med/MICU2-6FL-B2.html'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = 'MICU2-6FL-B2'\n",
    "df_locat = df[df['dataset_location'] == location].copy()\n",
    "df_locat['y_value_1'] = np.where(df_locat['y_value'] == 1, df_locat['SpO2'], float('nan') )\n",
    "\n",
    "traces = []\n",
    "\n",
    "for i, col in enumerate(['SpO2', 'SpO2_moving_avg']):\n",
    "    traces.append(go.Scatter(\n",
    "                    x = df_locat.dataset_datetime,\n",
    "                    y = df_locat[col],\n",
    "                    mode = 'lines',\n",
    "                    name = col\n",
    "                    ))\n",
    "    \n",
    "traces.append(go.Scatter(\n",
    "            x = df_locat.dataset_datetime,\n",
    "            y = df_locat.y_value_1,\n",
    "            mode = 'markers',\n",
    "            marker = dict(color = 'rgb(255,0,0)'),\n",
    "            name = \"'y'\"\n",
    "            ))\n",
    "\n",
    "traces.append(go.Scatter(\n",
    "                    x = df_locat.dataset_datetime,\n",
    "                    y = df_locat['SpO2_percent_change'],\n",
    "                    mode = 'lines',\n",
    "                    name = \"'SpO2_percent_change'\",\n",
    "                    yaxis = 'y2' \n",
    "                    ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = location,\n",
    "    yaxis2=dict(\n",
    "        overlaying='y',\n",
    "        color = '',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data = traces, layout = layout)\n",
    "plot(fig, filename = location + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, t_moving = '180s', t_before = '600s', n_before = 6):\n",
    "    data = df.copy()\n",
    "    cols = ['Respiratory Rate', 'Mean Airway Pressure', 'Inspired Tidal Volume', 'SpO2']\n",
    "    \n",
    "    # Moving Average ############################################################################################\n",
    "    data.sort_values(by = ['dataset_location','dataset_datetime'], inplace = True)\n",
    "    data.index = data['dataset_datetime']\n",
    "    mean = data.groupby('dataset_location')[cols].rolling(t_moving).mean().reset_index()\n",
    "    #mean.rename(columns = {col: '{}_{}'.format(col, 'moving_mean_avg') for col in (cols)}, inplace = True)\n",
    "    sd = data.groupby('dataset_location')[cols].rolling(t_moving).std().reset_index()\n",
    "    #sd.rename(columns = {col: '{}_{}'.format(col, 'moving_sd_avg') for col in (cols)}, inplace = True)\n",
    "    \n",
    "    for i, col in enumerate(cols):\n",
    "        colname = col + \"_moving_mean_avg\"\n",
    "        data[colname] = mean[col]\n",
    "        colname = col + \"_moving_sd_avg\"\n",
    "        data[colname] = sd[col]\n",
    "    \n",
    "    # Average Before ###########################################################################################\n",
    "    from datetime import timedelta\n",
    "    mean_bf = data.groupby(['dataset_location'])[cols].rolling(t_before).mean().reset_index()\n",
    "    sd_bf = data.groupby(['dataset_location'])[cols].rolling(t_before).std().reset_index()\n",
    "    \n",
    "    time_delta = []\n",
    "    for i in range(1,n_before+1):\n",
    "        time_delta.append(int(t_before[0:3])*i)\n",
    "    \n",
    "    \n",
    "    for i, s in enumerate(time_delta):\n",
    "        col_name = 'datetime_' + str(s) + \"s_bf\"\n",
    "        data[col_name] = data['dataset_datetime'] - timedelta(seconds = s)\n",
    "        \n",
    "        mean_df = mean_bf.copy()\n",
    "        mean_df = mean_df.rename(columns = {'dataset_datetime':col_name})\n",
    "        mean_df.rename(columns={col:'{}_{}'.format(col, 'mean' + str(s) +'s') for col in (cols)}, inplace=True)\n",
    "        data = pd.merge(left = data, right = mean_df, how='left', left_on = [col_name, 'dataset_location'],\n",
    "                      right_on = [col_name, 'dataset_location'])\n",
    "        \n",
    "        std_df = sd_bf.copy()\n",
    "        std_df = std_df.rename(columns = {'dataset_datetime':col_name})\n",
    "        std_df.rename(columns={col:'{}_{}'.format(col,'std' + str(s) +'s') for col in (cols)}, inplace=True)\n",
    "        data = pd.merge(left = data, right = std_df, how='left', left_on = [col_name, 'dataset_location'],\n",
    "                      right_on = [col_name, 'dataset_location'])\n",
    "        \n",
    "    data.index = range(len(data))\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tniyomkarn/tensorflow/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c8809a389a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mADASYN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['dataset_location', 'Respiratory Rate', 'Mean Airway Pressure', 'Inspired Tidal Volume']\n",
    "features.extend(list(data.columns)[ncolumn:])\n",
    "features = [x for x in features if \"datetime\" not in x ]\n",
    "x_data = data[features]\n",
    "y_data = data['y_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "test_size = 0.25\n",
    "train_features, test_features, train_target, test_target = train_test_split(x_data, \n",
    "                                                                            y_data, \n",
    "                                                                            test_size = test_size, \n",
    "                                                                            random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "oversampling by SMOTE alorithm: creates aynthetic observations of the minority class by\n",
    "- Finding the k-nearest-neighbors for minority class observations (finding similar observations)\n",
    "- Randomly choosing one of the k-nearest-neighbors and using it to create a similar, \n",
    "but randomly tweaked, new observation. \n",
    "\"\"\"\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(train_features,\n",
    "                                                 train_target,\n",
    "                                                 test_size = test_size,\n",
    "                                                 random_state = seed)\n",
    "\n",
    "sm = SMOTE(random_state = seed, ratio = 1.0)  # class ratio of 1\n",
    "x_res, y_res = sm.fit_sample(x_train, y_train)\n",
    "print(y_train.value_counts(), np.bincount(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm gradient boosting\n",
    "clf = XGBClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_features)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(test_target, predictions)\n",
    "print(\"Accuracy: %.2f\" %(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multiple Processing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = moving_avg(df)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = check_y(df_new)\n",
    "(df_new['y_value'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
